{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Carregando resultados CAPABILIDADE**"
      ],
      "metadata": {
        "id": "QlwMVR-VmMzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lzWnBC7OmTJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "tUI_wTLsmYKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando os valores das variáveis a partir de um arquivo\n",
        "try:\n",
        "    with open('/content/drive/My Drive/knn_results.pkl', 'rb') as file:\n",
        "        data = pickle.load(file)\n",
        "        knn_macro_f1_scores = data['knn_macro_f1_scores']\n",
        "        knn_micro_f1_scores = data['knn_micro_f1_scores']\n",
        "        knn_balanced_accuracies = data['knn_balanced_accuracies']\n",
        "        knn_mcc_scores = data['knn_mcc_scores']\n",
        "        knn_best_params_list = data['knn_best_params_list']\n",
        "        knn_best_scores_list = data['knn_best_scores_list']\n",
        "        knn_mean_macro_f1 = data['knn_mean_macro_f1']\n",
        "        knn_std_macro_f1 = data['knn_std_macro_f1']\n",
        "        knn_mean_micro_f1 = data['knn_mean_micro_f1']\n",
        "        knn_std_micro_f1 = data['knn_std_micro_f1']\n",
        "        knn_mean_balanced_acc = data['knn_mean_balanced_acc']\n",
        "        knn_std_balanced_acc = data['knn_std_balanced_acc']\n",
        "        knn_mean_mcc = data['knn_mean_mcc']\n",
        "        knn_std_mcc = data['knn_std_mcc']\n",
        "        knn_best_overall_params = data['knn_best_overall_params']\n",
        "        knn_best_overall_score = data['knn_best_overall_score']\n",
        "except FileNotFoundError:\n",
        "    knn_macro_f1_scores = []\n",
        "    knn_micro_f1_scores = []\n",
        "    knn_balanced_accuracies = []\n",
        "    knn_mcc_scores = []\n",
        "    knn_best_params_list = []\n",
        "    knn_best_scores_list = []\n",
        "    knn_mean_macro_f1 = 0\n",
        "    knn_std_macro_f1 = 0\n",
        "    knn_mean_micro_f1 = 0\n",
        "    knn_std_micro_f1 = 0\n",
        "    knn_mean_balanced_acc = 0\n",
        "    knn_std_balanced_acc = 0\n",
        "    knn_mean_mcc = 0\n",
        "    knn_std_mcc = 0\n",
        "    knn_best_overall_params = None\n",
        "    knn_best_overall_score = 0\n"
      ],
      "metadata": {
        "id": "ojG8FJEgmans"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_macro_f1_scores"
      ],
      "metadata": {
        "id": "Wps5scdSpbtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho no Google Drive\n",
        "file_path = '/content/drive/My Drive/nb_results.pkl'\n",
        "\n",
        "# Carregando os valores das variáveis a partir de um arquivo\n",
        "try:\n",
        "    with open(file_path, 'rb') as file:\n",
        "        data = pickle.load(file)\n",
        "        nb_macro_f1_scores = data['nb_macro_f1_scores']\n",
        "        nb_micro_f1_scores = data['nb_micro_f1_scores']\n",
        "        nb_balanced_accuracies = data['nb_balanced_accuracies']\n",
        "        nb_mcc_scores = data['nb_mcc_scores']\n",
        "        nb_best_params_list = data['nb_best_params_list']\n",
        "        nb_best_scores_list = data['nb_best_scores_list']\n",
        "        nb_mean_macro_f1 = data['nb_mean_macro_f1']\n",
        "        nb_std_macro_f1 = data['nb_std_macro_f1']\n",
        "        nb_mean_micro_f1 = data['nb_mean_micro_f1']\n",
        "        nb_std_micro_f1 = data['nb_std_micro_f1']\n",
        "        nb_mean_balanced_acc = data['nb_mean_balanced_acc']\n",
        "        nb_std_balanced_acc = data['nb_std_balanced_acc']\n",
        "        nb_mean_mcc = data['nb_mean_mcc']\n",
        "        nb_std_mcc = data['nb_std_mcc']\n",
        "        nb_best_overall_params = data['nb_best_overall_params']\n",
        "        nb_best_overall_score = data['nb_best_overall_score']\n",
        "except FileNotFoundError:\n",
        "    nb_macro_f1_scores = []\n",
        "    nb_micro_f1_scores = []\n",
        "    nb_balanced_accuracies = []\n",
        "    nb_mcc_scores = []\n",
        "    nb_best_params_list = []\n",
        "    nb_best_scores_list = []\n",
        "    nb_mean_macro_f1 = 0\n",
        "    nb_std_macro_f1 = 0\n",
        "    nb_mean_micro_f1 = 0\n",
        "    nb_std_micro_f1 = 0\n",
        "    nb_mean_balanced_acc = 0\n",
        "    nb_std_balanced_acc = 0\n",
        "    nb_mean_mcc = 0\n",
        "    nb_std_mcc = 0\n",
        "    nb_best_overall_params = None\n",
        "    nb_best_overall_score = 0"
      ],
      "metadata": {
        "id": "fjBpoLiKmc8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho no Google Drive\n",
        "file_path = '/content/drive/My Drive/dt_results.pkl'\n",
        "\n",
        "# Carregando os valores das variáveis a partir de um arquivo\n",
        "try:\n",
        "    with open(file_path, 'rb') as file:\n",
        "        data = pickle.load(file)\n",
        "        dt_macro_f1_scores = data['dt_macro_f1_scores']\n",
        "        dt_micro_f1_scores = data['dt_micro_f1_scores']\n",
        "        dt_balanced_accuracies = data['dt_balanced_accuracies']\n",
        "        dt_mcc_scores = data['dt_mcc_scores']\n",
        "        dt_best_params_list = data['dt_best_params_list']\n",
        "        dt_best_scores_list = data['dt_best_scores_list']\n",
        "        dt_mean_macro_f1 = data['dt_mean_macro_f1']\n",
        "        dt_std_macro_f1 = data['dt_std_macro_f1']\n",
        "        dt_mean_micro_f1 = data['dt_mean_micro_f1']\n",
        "        dt_std_micro_f1 = data['dt_std_micro_f1']\n",
        "        dt_mean_balanced_acc = data['dt_mean_balanced_acc']\n",
        "        dt_std_balanced_acc = data['dt_std_balanced_acc']\n",
        "        dt_mean_mcc = data['dt_mean_mcc']\n",
        "        dt_std_mcc = data['dt_std_mcc']\n",
        "        dt_best_overall_params = data['dt_best_overall_params']\n",
        "        dt_best_overall_score = data['dt_best_overall_score']\n",
        "except FileNotFoundError:\n",
        "    dt_macro_f1_scores = []\n",
        "    dt_micro_f1_scores = []\n",
        "    dt_balanced_accuracies = []\n",
        "    dt_mcc_scores = []\n",
        "    dt_best_params_list = []\n",
        "    dt_best_scores_list = []\n",
        "    dt_mean_macro_f1 = 0\n",
        "    dt_std_macro_f1 = 0\n",
        "    dt_mean_micro_f1 = 0\n",
        "    dt_std_micro_f1 = 0\n",
        "    dt_mean_balanced_acc = 0\n",
        "    dt_std_balanced_acc = 0\n",
        "    dt_mean_mcc = 0\n",
        "    dt_std_mcc = 0\n",
        "    dt_best_overall_params = None\n",
        "    dt_best_overall_score = 0\n"
      ],
      "metadata": {
        "id": "DKcDVi0jmfi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho no Google Drive\n",
        "file_path = '/content/drive/My Drive/lr_results.pkl'\n",
        "\n",
        "# Carregando os valores das variáveis a partir de um arquivo\n",
        "try:\n",
        "    with open(file_path, 'rb') as file:\n",
        "        data = pickle.load(file)\n",
        "        lr_macro_f1_scores = data['lr_macro_f1_scores']\n",
        "        lr_micro_f1_scores = data['lr_micro_f1_scores']\n",
        "        lr_balanced_accuracies = data['lr_balanced_accuracies']\n",
        "        lr_mcc_scores = data['lr_mcc_scores']\n",
        "        lr_best_params_list = data['lr_best_params_list']\n",
        "        lr_best_scores_list = data['lr_best_scores_list']\n",
        "        lr_mean_macro_f1 = data['lr_mean_macro_f1']\n",
        "        lr_std_macro_f1 = data['lr_std_macro_f1']\n",
        "        lr_mean_micro_f1 = data['lr_mean_micro_f1']\n",
        "        lr_std_micro_f1 = data['lr_std_micro_f1']\n",
        "        lr_mean_balanced_acc = data['lr_mean_balanced_acc']\n",
        "        lr_std_balanced_acc = data['lr_std_balanced_acc']\n",
        "        lr_mean_mcc = data['lr_mean_mcc']\n",
        "        lr_std_mcc = data['lr_std_mcc']\n",
        "        lr_best_overall_params = data['lr_best_overall_params']\n",
        "        lr_best_overall_score = data['lr_best_overall_score']\n",
        "except FileNotFoundError:\n",
        "    lr_macro_f1_scores = []\n",
        "    lr_micro_f1_scores = []\n",
        "    lr_balanced_accuracies = []\n",
        "    lr_mcc_scores = []\n",
        "    lr_best_params_list = []\n",
        "    lr_best_scores_list = []\n",
        "    lr_mean_macro_f1 = 0\n",
        "    lr_std_macro_f1 = 0\n",
        "    lr_mean_micro_f1 = 0\n",
        "    lr_std_micro_f1 = 0\n",
        "    lr_mean_balanced_acc = 0\n",
        "    lr_std_balanced_acc = 0\n",
        "    lr_mean_mcc = 0\n",
        "    lr_std_mcc = 0\n",
        "    lr_best_overall_params = None\n",
        "    lr_best_overall_score = 0\n"
      ],
      "metadata": {
        "id": "t4tyskzOmiMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho no Google Drive\n",
        "file_path = '/content/drive/My Drive/mlp_results.pkl'\n",
        "\n",
        "# Carregando os valores das variáveis a partir de um arquivo\n",
        "try:\n",
        "    with open(file_path, 'rb') as file:\n",
        "        data = pickle.load(file)\n",
        "        mlp_macro_f1_scores = data['mlp_macro_f1_scores']\n",
        "        mlp_micro_f1_scores = data['mlp_micro_f1_scores']\n",
        "        mlp_balanced_accuracies = data['mlp_balanced_accuracies']\n",
        "        mlp_mcc_scores = data['mlp_mcc_scores']\n",
        "        mlp_best_params_list = data['mlp_best_params_list']\n",
        "        mlp_best_scores_list = data['mlp_best_scores_list']\n",
        "        mlp_mean_macro_f1 = data['mlp_mean_macro_f1']\n",
        "        mlp_std_macro_f1 = data['mlp_std_macro_f1']\n",
        "        mlp_mean_micro_f1 = data['mlp_mean_micro_f1']\n",
        "        mlp_std_micro_f1 = data['mlp_std_micro_f1']\n",
        "        mlp_mean_balanced_acc = data['mlp_mean_balanced_acc']\n",
        "        mlp_std_balanced_acc = data['mlp_std_balanced_acc']\n",
        "        mlp_mean_mcc = data['mlp_mean_mcc']\n",
        "        mlp_std_mcc = data['mlp_std_mcc']\n",
        "        mlp_best_overall_params = data['mlp_best_overall_params']\n",
        "        mlp_best_overall_score = data['mlp_best_overall_score']\n",
        "except FileNotFoundError:\n",
        "    mlp_macro_f1_scores = []\n",
        "    mlp_micro_f1_scores = []\n",
        "    mlp_balanced_accuracies = []\n",
        "    mlp_mcc_scores = []\n",
        "    mlp_best_params_list = []\n",
        "    mlp_best_scores_list = []\n",
        "    mlp_mean_macro_f1 = 0\n",
        "    mlp_std_macro_f1 = 0\n",
        "    mlp_mean_micro_f1 = 0\n",
        "    mlp_std_micro_f1 = 0\n",
        "    mlp_mean_balanced_acc = 0\n",
        "    mlp_std_balanced_acc = 0\n",
        "    mlp_mean_mcc = 0\n",
        "    mlp_std_mcc = 0\n",
        "    mlp_best_overall_params = None\n",
        "    mlp_best_overall_score = 0\n"
      ],
      "metadata": {
        "id": "4sNzgrmomkkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho no Google Drive\n",
        "file_path = '/content/drive/My Drive/svc_results.pkl'\n",
        "\n",
        "# Carregando os valores das variáveis a partir de um arquivo\n",
        "try:\n",
        "    with open(file_path, 'rb') as file:\n",
        "        data = pickle.load(file)\n",
        "        svc_macro_f1_scores = data['svc_macro_f1_scores']\n",
        "        svc_micro_f1_scores = data['svc_micro_f1_scores']\n",
        "        svc_balanced_accuracies = data['svc_balanced_accuracies']\n",
        "        svc_mcc_scores = data['svc_mcc_scores']\n",
        "        svc_best_params_list = data['svc_best_params_list']\n",
        "        svc_best_scores_list = data['svc_best_scores_list']\n",
        "        svc_mean_macro_f1 = data['svc_mean_macro_f1']\n",
        "        svc_std_macro_f1 = data['svc_std_macro_f1']\n",
        "        svc_mean_micro_f1 = data['svc_mean_micro_f1']\n",
        "        svc_std_micro_f1 = data['svc_std_micro_f1']\n",
        "        svc_mean_balanced_acc = data['svc_mean_balanced_acc']\n",
        "        svc_std_balanced_acc = data['svc_std_balanced_acc']\n",
        "        svc_mean_mcc = data['svc_mean_mcc']\n",
        "        svc_std_mcc = data['svc_std_mcc']\n",
        "        svc_best_overall_params = data['svc_best_overall_params']\n",
        "        svc_best_overall_score = data['svc_best_overall_score']\n",
        "except FileNotFoundError:\n",
        "    svc_macro_f1_scores = []\n",
        "    svc_micro_f1_scores = []\n",
        "    svc_balanced_accuracies = []\n",
        "    svc_mcc_scores = []\n",
        "    svc_best_params_list = []\n",
        "    svc_best_scores_list = []\n",
        "    svc_mean_macro_f1 = 0\n",
        "    svc_std_macro_f1 = 0\n",
        "    svc_mean_micro_f1 = 0\n",
        "    svc_std_micro_f1 = 0\n",
        "    svc_mean_balanced_acc = 0\n",
        "    svc_std_balanced_acc = 0\n",
        "    svc_mean_mcc = 0\n",
        "    svc_std_mcc = 0\n",
        "    svc_best_overall_params = None\n",
        "    svc_best_overall_score = 0\n"
      ],
      "metadata": {
        "id": "efPzpPAOmnk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho no Google Drive\n",
        "file_path = '/content/drive/My Drive/rf_results.pkl'\n",
        "\n",
        "# Carregando os valores das variáveis a partir de um arquivo\n",
        "try:\n",
        "    with open(file_path, 'rb') as file:\n",
        "        data = pickle.load(file)\n",
        "        rf_macro_f1_scores = data['rf_macro_f1_scores']\n",
        "        rf_micro_f1_scores = data['rf_micro_f1_scores']\n",
        "        rf_balanced_accuracies = data['rf_balanced_accuracies']\n",
        "        rf_mcc_scores = data['rf_mcc_scores']\n",
        "        rf_best_params_list = data['rf_best_params_list']\n",
        "        rf_best_scores_list = data['rf_best_scores_list']\n",
        "        rf_mean_macro_f1 = data['rf_mean_macro_f1']\n",
        "        rf_std_macro_f1 = data['rf_std_macro_f1']\n",
        "        rf_mean_micro_f1 = data['rf_mean_micro_f1']\n",
        "        rf_std_micro_f1 = data['rf_std_micro_f1']\n",
        "        rf_mean_balanced_acc = data['rf_mean_balanced_acc']\n",
        "        rf_std_balanced_acc = data['rf_std_balanced_acc']\n",
        "        rf_mean_mcc = data['rf_mean_mcc']\n",
        "        rf_std_mcc = data['rf_std_mcc']\n",
        "        rf_best_overall_params = data['rf_best_overall_params']\n",
        "        rf_best_overall_score = data['rf_best_overall_score']\n",
        "except FileNotFoundError:\n",
        "    rf_macro_f1_scores = []\n",
        "    rf_micro_f1_scores = []\n",
        "    rf_balanced_accuracies = []\n",
        "    rf_mcc_scores = []\n",
        "    rf_best_params_list = []\n",
        "    rf_best_scores_list = []\n",
        "    rf_mean_macro_f1 = 0\n",
        "    rf_std_macro_f1 = 0\n",
        "    rf_mean_micro_f1 = 0\n",
        "    rf_std_micro_f1 = 0\n",
        "    rf_mean_balanced_acc = 0\n",
        "    rf_std_balanced_acc = 0\n",
        "    rf_mean_mcc = 0\n",
        "    rf_std_mcc = 0\n",
        "    rf_best_overall_params = None\n",
        "    rf_best_overall_score = 0\n"
      ],
      "metadata": {
        "id": "6RIG8Oucmsle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "--tEWjtim7og"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sumarização dos resultados**"
      ],
      "metadata": {
        "id": "id2uq28Sm98S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Macro f1**"
      ],
      "metadata": {
        "id": "spDoFkyGnEjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "resultados_macrof1 = pd.DataFrame({'Arvore': dt_macro_f1_scores, 'Random forest': rf_macro_f1_scores,\n",
        "                           'KNN': knn_macro_f1_scores, 'Logistica': lr_macro_f1_scores,\n",
        "                           'SVM': svc_macro_f1_scores, 'Rede neural': mlp_macro_f1_scores, 'Naive Bayes':nb_macro_f1_scores})\n",
        "resultados_macrof1"
      ],
      "metadata": {
        "id": "zbkpuGq-nCv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_macrof1.describe()"
      ],
      "metadata": {
        "id": "W7F7gytmr-hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores = [\n",
        "    dt_macro_f1_scores, rf_macro_f1_scores, knn_macro_f1_scores,\n",
        "    lr_macro_f1_scores, svc_macro_f1_scores, mlp_macro_f1_scores, nb_macro_f1_scores\n",
        "]\n",
        "\n",
        "# Nomes dos modelos\n",
        "models = ['Árvore', 'Random Forest', 'KNN', 'Logística', 'SVM', 'Rede Neural', 'Naive Bayes']\n"
      ],
      "metadata": {
        "id": "xNOdgZOno939"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação dos DataFrames para cada métrica\n",
        "resultados_micro_f1 = pd.DataFrame({\n",
        "    'Árvore': dt_micro_f1_scores,\n",
        "    'Random forest': rf_micro_f1_scores,\n",
        "    'KNN': knn_micro_f1_scores,\n",
        "    'Logística': lr_micro_f1_scores,\n",
        "    'SVM': svc_micro_f1_scores,\n",
        "    'Rede neural': mlp_micro_f1_scores,\n",
        "    'Naive Bayes': nb_micro_f1_scores\n",
        "})\n",
        "\n",
        "resultados_balanced_accuracy = pd.DataFrame({\n",
        "    'Árvore': dt_balanced_accuracies,\n",
        "    'Random forest': rf_balanced_accuracies,\n",
        "    'KNN': knn_balanced_accuracies,\n",
        "    'Logística': lr_balanced_accuracies,\n",
        "    'SVM': svc_balanced_accuracies,\n",
        "    'Rede neural': mlp_balanced_accuracies,\n",
        "    'Naive Bayes': nb_balanced_accuracies\n",
        "})\n",
        "\n",
        "resultados_mcc = pd.DataFrame({\n",
        "    'Árvore': dt_mcc_scores,\n",
        "    'Random forest': rf_mcc_scores,\n",
        "    'KNN': knn_mcc_scores,\n",
        "    'Logística': lr_mcc_scores,\n",
        "    'SVM': svc_mcc_scores,\n",
        "    'Rede neural': mlp_mcc_scores,\n",
        "    'Naive Bayes': nb_mcc_scores\n",
        "})"
      ],
      "metadata": {
        "id": "QeZpk8tUfFHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibição dos DataFrames\n",
        "print(resultados_micro_f1.describe())"
      ],
      "metadata": {
        "id": "rbPO7tZgfLY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resultados_balanced_accuracy.describe())"
      ],
      "metadata": {
        "id": "ac7MsSK0fMr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resultados_mcc.describe())"
      ],
      "metadata": {
        "id": "wEK8AIYNfN8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotando o boxplot\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.boxplot(f1_scores, labels=models, patch_artist=True)\n",
        "plt.ylabel('Macro F1-Score')\n",
        "plt.title('Distribuição de Macro F1-Scores entre Modelos')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cB4IUD07pA7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Teste de normalidade**"
      ],
      "metadata": {
        "id": "QWRTEcOkseAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.05"
      ],
      "metadata": {
        "id": "VMd4Fx1vsdzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import shapiro\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "06Fy1Xwisdv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Agrupando os F1-scores em uma lista\n",
        "f1_scores = [\n",
        "    dt_macro_f1_scores, rf_macro_f1_scores, knn_macro_f1_scores,\n",
        "    lr_macro_f1_scores, svc_macro_f1_scores, mlp_macro_f1_scores, nb_macro_f1_scores\n",
        "]\n",
        "\n",
        "# Nomes dos modelos\n",
        "models = ['Árvore', 'Random Forest', 'KNN', 'Logística', 'SVM', 'Rede Neural', 'Naive Bayes']\n",
        "\n",
        "# Aplicando o teste de Shapiro-Wilk e imprimindo os resultados\n",
        "for model, scores in zip(models, f1_scores):\n",
        "    stat, p = shapiro(scores)\n",
        "    print(f'{model}: Teste de Shapiro-Wilk -> Estatística={stat:.3f}, p-valor={p:.3f}')"
      ],
      "metadata": {
        "id": "51-VwM64s4Vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model, scores in zip(models, f1_scores):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.displot(scores, kind='kde')\n",
        "    plt.title(f'Distribuição dos Macro F1-Scores - {model}')\n",
        "    plt.xlabel('Macro F1-Score')\n",
        "    plt.ylabel('Densidade')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qKHsegdutpUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-posthocs\n"
      ],
      "metadata": {
        "id": "EYuppOiyy3Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "friedman_result = stats.friedmanchisquare(\n",
        "    dt_macro_f1_scores, rf_macro_f1_scores, knn_macro_f1_scores, lr_macro_f1_scores,\n",
        "    svc_macro_f1_scores, mlp_macro_f1_scores, nb_macro_f1_scores\n",
        ")\n",
        "\n",
        "friedman_result\n"
      ],
      "metadata": {
        "id": "4rStAjFw41gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Aplicando o teste de Friedman\n",
        "friedman_result = stats.friedmanchisquare(\n",
        "    resultados_macrof1['Arvore'], resultados_macrof1['Random forest'], resultados_macrof1['KNN'],\n",
        "    resultados_macrof1['Logistica'], resultados_macrof1['SVM'], resultados_macrof1['Rede neural'], resultados_macrof1['Naive Bayes']\n",
        ")\n",
        "\n",
        "print(f\"Estatística: {friedman_result.statistic}\")\n",
        "print(f\"Valor p: {friedman_result.pvalue}\")\n"
      ],
      "metadata": {
        "id": "F8D2H0rh48eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "import scikit_posthocs as sp\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Supondo que você já tenha o DataFrame `resultados_macrof1` com seus dados\n",
        "resultados_macrof1 = pd.DataFrame({\n",
        "    'Arvore': dt_macro_f1_scores,\n",
        "    'RF': rf_macro_f1_scores,\n",
        "    'KNN': knn_macro_f1_scores,\n",
        "    'Logistica': lr_macro_f1_scores,\n",
        "    'SVM': svc_macro_f1_scores,\n",
        "    'Rede neural': mlp_macro_f1_scores,\n",
        "    'NB': nb_macro_f1_scores\n",
        "})\n",
        "\n",
        "# Aplicando o teste de Friedman\n",
        "friedman_result = stats.friedmanchisquare(\n",
        "    resultados_macrof1['Arvore'], resultados_macrof1['RF'], resultados_macrof1['KNN'],\n",
        "    resultados_macrof1['Logistica'], resultados_macrof1['SVM'], resultados_macrof1['Rede neural'], resultados_macrof1['NB']\n",
        ")\n",
        "\n",
        "print(f\"Estatística: {friedman_result.statistic}\")\n",
        "print(f\"Valor p: {friedman_result.pvalue}\")\n",
        "\n",
        "# Realizando o teste de Nemenyi\n",
        "nemenyi_result = sp.posthoc_nemenyi_friedman(resultados_macrof1.values)\n",
        "\n",
        "# Adicionando os nomes dos modelos ao resultado\n",
        "nemenyi_result.index = resultados_macrof1.columns\n",
        "nemenyi_result.columns = resultados_macrof1.columns\n",
        "\n",
        "# Exibindo os resultados\n",
        "print(nemenyi_result)\n",
        "\n",
        "# Visualizando os resultados do teste de Nemenyi\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(nemenyi_result, annot=True, cmap=\"coolwarm\", cbar=False, fmt=\".2f\")\n",
        "plt.title('Teste de Nemenyi')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Vy8GV3WU9dK0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}